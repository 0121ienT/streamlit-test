import streamlit as st
import pandas as pd
import pickle
import json
import warnings

# T·∫Øt c√°c c·∫£nh b√°o kh√¥ng c·∫ßn thi·∫øt
warnings.filterwarnings('ignore')

# T·∫£i m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán (v·∫´n t·ª´ .pkl)
try:
    # <<< THAY ƒê·ªîI: ƒê·∫£m b·∫£o t√™n t·ªáp n√†y kh·ªõp v·ªõi t·ªáp b·∫°n ƒë√£ t·∫°o (v√≠ d·ª•: stress_model.pkl)
    with open('stress_trained.sav', 'rb') as f_model:
        model = pickle.load(f_model)
except FileNotFoundError:
    # <<< THAY ƒê·ªîI: C·∫≠p nh·∫≠t th√¥ng b√°o l·ªói cho nh·∫•t qu√°n
    st.error("L·ªói: Kh√¥ng t√¨m th·∫•y t·ªáp m√¥ h√¨nh 'stress_model.pkl'.")
    st.error("H√£y ƒë·∫£m b·∫£o b·∫°n ƒë√£ ch·∫°y t·ªáp 'create_model.py' ho·∫∑c 'train_model.py' ƒë·ªÉ t·∫°o ra t·ªáp n√†y.")
    st.stop()

# --- T·∫¢I TH√îNG TIN T·ª™ FILE .JSON ---
try:
    with open('data_info.json', 'r', encoding='utf-8') as f_info:
        data_info = json.load(f_info) # S·ª≠ d·ª•ng json.load
    
    feature_names = data_info['feature_names']
    stats = data_info['stats']
except FileNotFoundError:
    st.error("L·ªói: Kh√¥ng t√¨m th·∫•y t·ªáp th√¥ng tin 'data_info.json'.")
    st.error("H√£y ƒë·∫£m b·∫£o b·∫°n ƒë√£ t·∫°o t·ªáp n√†y th·ªß c√¥ng ho·∫∑c ch·∫°y t·ªáp 'train_model.py'.")
    st.stop()
except json.JSONDecodeError:
    st.error("L·ªói: T·ªáp 'data_info.json' kh√¥ng ph·∫£i l√† t·ªáp JSON h·ª£p l·ªá.")
    st.stop()

# ƒê·ªãnh nghƒ©a nh√£n cho c√°c m·ª©c ƒë·ªô stress
STRESS_MAP = {
    "0": "Th·∫•p (Low)",
    "1": "Trung b√¨nh (Medium)",
    "2": "Cao (High)"
}

# <<< TH√äM M·ªöI: Dictionary ch·ª©a c√°c l·ªùi gi·∫£i th√≠ch
STRESS_EXPLANATIONS = {
    "0": "T√¨nh tr·∫°ng tinh th·∫ßn c·ªßa b·∫°n r·∫•t t·ªët. M·ª©c ƒë·ªô stress th·∫•p cho th·∫•y b·∫°n ƒëang ki·ªÉm so√°t t·ªët c√°c y·∫øu t·ªë √°p l·ª±c trong cu·ªôc s·ªëng. H√£y ti·∫øp t·ª•c duy tr√¨ th√≥i quen sinh ho·∫°t v√† suy nghƒ© t√≠ch c·ª±c!",
    "1": "B·∫°n ƒëang c√≥ d·∫•u hi·ªáu stress ·ªü m·ª©c ƒë·ªô v·ª´a ph·∫£i. ƒê√¢y c√≥ th·ªÉ l√† ph·∫£n ·ª©ng b√¨nh th∆∞·ªùng tr∆∞·ªõc c√°c √°p l·ª±c, nh∆∞ng b·∫°n n√™n ch√∫ √Ω. H√£y d√†nh th·ªùi gian th∆∞ gi√£n, xem x√©t l·∫°i kh·ªëi l∆∞·ª£ng c√¥ng vi·ªác/h·ªçc t·∫≠p v√† chia s·∫ª v·ªõi b·∫°n b√®.",
    "2": "M·ª©c ƒë·ªô stress c·ªßa b·∫°n ƒëang ·ªü m·ª©c cao. ƒê√¢y l√† m·ªôt c·∫£nh b√°o quan tr·ªçng. Stress cao k√©o d√†i c√≥ th·ªÉ ·∫£nh h∆∞·ªüng nghi√™m tr·ªçng ƒë·∫øn s·ª©c kh·ªèe th·ªÉ ch·∫•t v√† tinh th·∫ßn. B·∫°n n√™n gi·∫£m t·∫£i c√¥ng vi·ªác ngay l·∫≠p t·ª©c, t√¨m ki·∫øm s·ª± gi√∫p ƒë·ª° t·ª´ chuy√™n gia ho·∫∑c ng∆∞·ªùi th√¢n."
}

# --- Giao di·ªán ·ª©ng d·ª•ng Streamlit ---
st.set_page_config(page_title="D·ª± ƒëo√°n M·ª©c ƒë·ªô Stress", layout="wide")
st.title("·ª®ng d·ª•ng D·ª± ƒëo√°n M·ª©c ƒë·ªô Stress ü©∫")
st.write("S·ª≠ d·ª•ng c√°c thanh tr∆∞·ª£t b√™n d∆∞·ªõi ƒë·ªÉ nh·∫≠p v√†o c√°c ch·ªâ s·ªë c·ªßa b·∫°n v√† nh·∫•n 'D·ª± ƒëo√°n' ƒë·ªÉ xem k·∫øt qu·∫£.")

# T·∫°o 2 c·ªôt ƒë·ªÉ giao di·ªán ƒë·ª° d√†i
col1, col2 = st.columns(2)

# Dictionary ƒë·ªÉ l∆∞u tr·ªØ input c·ªßa ng∆∞·ªùi d√πng
input_data = {}

# (Gi·ªØ nguy√™n ph·∫ßn t·∫°o sliders)
mid_point = len(feature_names) // 2
features_col1 = feature_names[:mid_point]
features_col2 = feature_names[mid_point:]

with col1:
    st.header("C√°c ch·ªâ s·ªë (Ph·∫ßn 1)")
    for feature in features_col1:
        min_val = int(stats[feature]['min'])
        max_val = int(stats[feature]['max'])
        mean_val = int(stats[feature]['mean'])
        
        input_data[feature] = st.slider(
            label=feature.replace("_", " ").capitalize(),
            min_value=min_val,
            max_value=max_val,
            value=mean_val,
            step=1
        )

with col2:
    st.header("C√°c ch·ªâ s·ªë (Ph·∫ßn 2)")
    for feature in features_col2:
        min_val = int(stats[feature]['min'])
        max_val = int(stats[feature]['max'])
        mean_val = int(stats[feature]['mean'])
        
        input_data[feature] = st.slider(
            label=feature.replace("_", " ").capitalize(),
            min_value=min_val,
            max_value=max_val,
            value=mean_val,
            step=1
        )

# N√∫t d·ª± ƒëo√°n
st.divider()
if st.button("D·ª± ƒëo√°n M·ª©c ƒë·ªô Stress", type="primary", use_container_width=True):
    # Chuy·ªÉn d·ªØ li·ªáu input th√†nh DataFrame
    input_df = pd.DataFrame([input_data])
    input_df = input_df[feature_names] 

    # Ch·∫°y m√¥ h√¨nh d·ª± ƒëo√°n
    try:
        prediction = model.predict(input_df)
        probabilities = model.predict_proba(input_df)[0]
        
        # <<< --- KH·ªêI LOGIC M·ªöI THAY TH·∫æ --- >>>
        
        # L·∫•y l·ªõp ƒë∆∞·ª£c d·ª± ƒëo√°n (v√≠ d·ª•: 0, 1, ho·∫∑c 2)
        predicted_class = prediction[0]
        
        # L·∫•y nh√£n t∆∞∆°ng ·ª©ng (v√≠ d·ª•: "Trung b√¨nh (Medium)")
        result_label = STRESS_MAP.get(str(predicted_class), "Kh√¥ng x√°c ƒë·ªãnh")
        
        # L·∫•y x√°c su·∫•t cao nh·∫•t (x√°c su·∫•t c·ªßa l·ªõp ƒë∆∞·ª£c d·ª± ƒëo√°n)
        max_probability = probabilities[predicted_class]
        
        # L·∫•y l·ªùi gi·∫£i th√≠ch t∆∞∆°ng ·ª©ng
        explanation = STRESS_EXPLANATIONS.get(str(predicted_class), "Kh√¥ng c√≥ l·ªùi gi·∫£i th√≠ch cho k·∫øt qu·∫£ n√†y.")
        
        # --- Hi·ªÉn th·ªã k·∫øt qu·∫£ ---
        
        # 1. Hi·ªÉn th·ªã k·∫øt qu·∫£ ch√≠nh
        st.subheader(f"K·∫øt qu·∫£ D·ª± ƒëo√°n: M·ª©c ƒë·ªô Stress l√† '{result_label}'")
        
        # 2. Hi·ªÉn th·ªã ƒë·ªô ch·∫Øc ch·∫Øn (x√°c su·∫•t)
        percent_value = f"{max_probability * 100:.2f}%"
        st.metric(label="ƒê·ªô ch·∫Øc ch·∫Øn c·ªßa m√¥ h√¨nh", value=percent_value)
        
        # 3. Hi·ªÉn th·ªã l·ªùi gi·∫£i th√≠ch
        st.subheader("L·ªùi gi·∫£i th√≠ch & Khuy·∫øn ngh·ªã:")
        st.info(explanation)
        
        # <<< --- K·∫æT TH√öC KH·ªêI LOGIC M·ªöI --- >>>

    except Exception as e:
        st.error(f"ƒê√£ x·∫£y ra l·ªói trong qu√° tr√¨nh d·ª± ƒëo√°n: {e}")